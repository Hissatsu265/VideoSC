{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4e1eb3-d868-4282-b58d-16b2b442213f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (4.46.1)\n",
      "Requirement already satisfied: datasets in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (3.3.2)\n",
      "Requirement already satisfied: accelerate in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (1.4.0)\n",
      "Collecting peft\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: filelock in /opt/tljh/user/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/tljh/user/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/tljh/user/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/tljh/user/lib/python3.10/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: xxhash in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/tljh/user/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: psutil in /opt/tljh/user/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/tljh/user/lib/python3.10/site-packages (from accelerate) (2.2.2+cu118)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/tljh/user/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/tljh/user/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/tljh/user/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/tljh/user/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/tljh/user/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/tljh/user/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/tljh/user/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/tljh/user/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/tljh/user/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/tljh/user/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/tljh/user/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/tljh/user/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/tljh/user/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (8.7.0.84)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/tljh/user/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/tljh/user/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/tljh/user/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/tljh/user/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/tljh/user/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /opt/tljh/user/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/tljh/user/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.8.86)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/tljh/user/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/tljh/user/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/tljh/user/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/tljh/user/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/tljh/user/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/tljh/user/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes, peft\n",
      "Successfully installed bitsandbytes-0.45.3 peft-0.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate peft bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a797eddc-52c8-4e6e-a1f5-ef13b06e0a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3cb6ae3f783473e9215e002bf7f434a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"hf://datasets/toanduc/t5-sumary-dataset/dataset.csv\")\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57cb7967-c525-4e1e-b94c-0961cc38e7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b971e19e1bf426c8f9f7bc8f3db6fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8948 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1144b5f8ebda4a9a8e93121b9c1f3b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/995 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"VietAI/vit5-base\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [doc for doc in examples[\"Original Text\"]]\n",
    "    targets = [doc for doc in examples[\"Summary\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    # print(labels)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    # print(model_inputs)\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac889808-d107-43a9-8625-79e9c78931cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 08:05:11.455570: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-09 08:05:11.455607: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-09 08:05:11.456364: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-09 08:05:11.460302: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336c398d1d144ddf9b8a88520f118e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa9fea8a8f54cc7a2442a9ec48af55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/904M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 226,835,712 || trainable%: 0.3900\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,  # Rank của LoRA\n",
    "    lora_alpha=32,  # Hệ số điều chỉnh\n",
    "    lora_dropout=0.1,  # Dropout để tránh overfitting\n",
    "    target_modules=[\"q\", \"v\"],  # Chỉ fine-tune một số layer quan trọng\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()  # Kiểm tra số tham số được fine-tune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98fc0d03-0bdb-49a8-8c29-64ea3b76e770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_iot13_toanlm/.local/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3755991/2186099578.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/opt/tljh/user/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/tljh/user/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1395' max='1395' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1395/1395 3:25:32, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.664600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.664600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.222600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.222600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/tljh/user/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/tljh/user/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/tljh/user/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/tljh/user/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/opt/tljh/user/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1395, training_loss=4.50813246422771, metrics={'train_runtime': 12339.3986, 'train_samples_per_second': 3.626, 'train_steps_per_second': 0.113, 'total_flos': 2.730520769200128e+16, 'train_loss': 4.50813246422771, 'epoch': 4.9906124273580685})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    # per_device_train_batch_size=8,\n",
    "    # per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    per_device_train_batch_size=2, \n",
    "    per_device_eval_batch_size=2,  \n",
    "    gradient_accumulation_steps=8,\n",
    "    fp16=True, \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a9fc940-efee-4f4c-88c5-2675c40ed1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Tuyển Việt Nam đứng im trên bảng xếp hạng FIFA\n",
      "Dù đánh bại Palestine trong dịp FIFA Days vừa qua, nhưng tuyển Việt Nam vẫn đứng vị trí 95 trên bảng xếp hạng của Liên đoàn bóng đá thế giới.\n",
      "Hai pha ghi bàn của Công Phượng và Phạm Tuấn giúp thầy trò HLV Philippe Troussier đánh bại các cầu thủ Palestine trong trận giao hữu trên sân Thiên Trường vừa qua.\n",
      "Chiến thắng này giúp tuyển Việt Nam được công thêm 4,91 điểm để nâng tổng số điểm lên 1.243,14. Tuy nhiên, \"Những chiến binh sao vàng\" vẫn giữ nguyên thứ hạng 95 trên bảng xếp hạng FIFA và top 15 châu Á.\n",
      "Điều này xuất phát từ việc các đội tuyển xếp trên thầy trò HLV Philippe Trousser cũng có được những kết quả tốt trong dịp FIFA Days vừa qua.\n",
      "Trong khi đó, thất bại trước tuyển Việt Nam khiến Palestine bị trừ 8,97 điểm và tụt 1 bậc, từ vị trí 96 xuống 97.\n",
      "Ở khu vực Đông Nam Á, ba đội tuyển gồm Thái Lan, Indonesia và Malaysia đều có sự thăng tiến so với tháng trước. Cụ thể, Thái Lan tăng từ 114 vươn lên 112 thế giới sau các trận đấu tại King's Cup. Indonesia tăng 3 bậc (lên vị trí thứ 147) sau trận thắng Kyrgyzstan. Malaysia cũng tăng lên vị trí thứ 134.\n",
      "Ở top 10, bảy vị trí đầu tiên không có sự xáo trộn khi ĐKVĐ World Cup Argentina vẫn trên đỉnh. Các đội tuyển xếp sau là Pháp, Brazil, Anh, Bỉ, Croatia, Hà Lan. Bồ Đào Nha qua mặt Italia để chiếm vị trí thứ 8, suất còn lại trong top 10 thuộc về Tây Ban Nha.\n",
      "Ở khu vực châu Á, Nhật Bản với 2 chiến thắng 4-1 trước Đức và 4-2 trước Thổ Nhĩ Kỳ giúp họ giữ top 1 châu lục đông dân nhất châu Á và vươn lên hạng 19 thế giới.\n",
      "Các vị trí tiếp theo thuộc về Iran (hạng 21), Hàn Quốc (26), Australia (27), Saudi Arabia (57)...\n",
      "Video giao hữu Việt Nam 2-0 Palestin (nguồn: FPT Play)\n",
      "\n",
      "Summary: Trong dịp FIFA Days vừa qua, tuyển Việt Nam vẫn đứng vị trí 95 trên bảng xếp hạng FIFA và top 15 châu Á. Điều này xuất phát từ việc các đội tuyển xếp trên thầy trò HLV Philippe Troussier vẫn giữ nguyên thứ hạng 95 trên bảng xếp hạng FIFA và top 15 châu Á.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def summarize(text):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    model.to(device)  # Đảm bảo model cũng trên GPU\n",
    "\n",
    "    output = model.generate(**inputs, max_length=128)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "test_text = dataset[\"test\"][0][\"Original Text\"]\n",
    "print(\"Input:\", test_text)\n",
    "print(\"Summary:\", summarize(test_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75d38231-8cd6-44c2-856e-487ec0a8c089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mô hình đã được lưu!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"/home/jupyter-iec_iot13_toanlm/cv_match/model.pth\")\n",
    "print(\"Mô hình đã được lưu!\")\n",
    "# //load lại mô hình\n",
    "# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"saved_model\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"saved_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feffd482-14f6-4529-90c9-8c70c3c2f5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: * là người mẫu đẹp trai, tôi là người mẫu đẹp trai. Tôi là người mẫu đẹp trai. Tôi là người mẫu đẹp trai. Tôi là người mẫu đẹp trai. Tôi là người mẫu đẹp trai. Tôi là người mẫu đẹp trai. Tôi là người mẫu đẹp trai. Tôi là người mẫu đẹp trai. Tôi là người mẫu đẹp trai. Tôi là người mẫu đẹp trai.\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary:\", summarize(\"tôi là người siêu đẹp trai\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de4ced1-7694-43ec-8ee2-0eab4f4d5d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
